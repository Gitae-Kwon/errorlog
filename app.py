# app.py â€” ì¥ì•  í˜„í™© ëŒ€ì‹œë³´ë“œ (KPI + í•„í„° + AgGrid ëª©ë¡/ìƒì„¸ + ì—…ë¡œë“œ/ì‚­ì œ + ì¤„ë°”ê¿ˆ í‘œì‹œ)

import os
import pandas as pd
import altair as alt
import streamlit as st
from datetime import datetime, timedelta
from sqlalchemy import create_engine, text

# AgGrid
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, JsCode

st.set_page_config(page_title="ì¥ì•  í˜„í™© ëŒ€ì‹œë³´ë“œ", page_icon="ğŸ“Š", layout="wide")
st.title("ğŸ“Š ì¥ì•  í˜„í™© ëŒ€ì‹œë³´ë“œ")
st.caption("KPI ì¹´ë“œ Â· í•„í„° Â· AgGrid ëª©ë¡/ìƒì„¸ Â· ì—…ë¡œë“œ/ì‚­ì œ Â· ì¤„ë°”ê¿ˆ í‘œì‹œ")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DB ì—°ê²° (secrets ì½ê¸° + SSL ê°•ì œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner=False)
def get_engine():
    s = st.secrets
    if "db" in s:
        cfg = s["db"];  host = cfg.get("HOST") or cfg.get("host")
        port = int(cfg.get("PORT") or cfg.get("port") or 3306)
        user = cfg.get("USER") or cfg.get("user")
        pw   = cfg.get("PASSWORD") or cfg.get("password")
        name = cfg.get("NAME") or cfg.get("name")
    elif "DB" in s:
        cfg = s["DB"];  host = cfg.get("DB_HOST") or cfg.get("HOST")
        port = int(cfg.get("DB_PORT") or cfg.get("PORT") or 3306)
        user = cfg.get("DB_USER") or cfg.get("USER")
        pw   = cfg.get("DB_PASSWORD") or cfg.get("PASSWORD")
        name = cfg.get("DB_NAME") or cfg.get("NAME")
    else:
        host = os.getenv("DB_HOST"); port = int(os.getenv("DB_PORT") or 3306)
        user = os.getenv("DB_USER"); pw = os.getenv("DB_PASSWORD"); name = os.getenv("DB_NAME")

    if not all([host, user, pw, name]):
        st.error("DB secretsê°€ ì—†ìŠµë‹ˆë‹¤. [db] ë˜ëŠ” [DB] ì„¹ì…˜ìœ¼ë¡œ HOST/PORT/USER/PASSWORD/NAMEì„ ë“±ë¡í•˜ì„¸ìš”.")
        st.stop()

    url = f"mysql+pymysql://{user}:{pw}@{host}:{port}/{name}?charset=utf8mb4"
    # MySQL 8 (caching_sha2_password) ì¸ì¦ ì˜¤ë¥˜ ë°©ì§€: SSL ê°•ì œ
    connect_args = {"ssl": {"ssl": True}}

    try:
        eng = create_engine(url, pool_pre_ping=True, connect_args=connect_args)
        with eng.connect() as conn:
            conn.execute(text("SELECT 1"))
        return eng
    except Exception as e:
        st.error(f"DB ì—°ê²° ì‹¤íŒ¨: {e}")
        st.stop()

engine = get_engine()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê³µí†µ ì¿¼ë¦¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(ttl=180, show_spinner=False)
def get_distinct_values():
    with engine.connect() as conn:
        platforms = pd.read_sql(text(
            "SELECT DISTINCT platform FROM incidents "
            "WHERE platform IS NOT NULL AND platform<>'' ORDER BY platform"
        ), conn)["platform"].tolist()
        locales = pd.read_sql(text(
            "SELECT DISTINCT locale FROM incidents "
            "WHERE locale IS NOT NULL AND locale<>'' ORDER BY locale"
        ), conn)["locale"].tolist()
        cats = pd.read_sql(text(
            "SELECT DISTINCT category FROM incidents "
            "WHERE category IS NOT NULL AND category<>'' ORDER BY category"
        ), conn)["category"].tolist()
    return platforms, locales, cats

PLATFORMS, LOCALES, CATEGORIES = get_distinct_values()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‚¬ì´ë“œë°” í•„í„°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("í•„í„°")
    today = datetime.now().date()
    default_from = today - timedelta(days=30)
    date_from, date_to = st.date_input("ê¸°ê°„(started_at)", value=(default_from, today))
    if isinstance(date_from, tuple):  # ì•ˆì „ì¥ì¹˜
        date_from, date_to = date_from

    sel_platforms = st.multiselect("í”Œë«í¼", options=PLATFORMS)
    sel_locales   = st.multiselect("ë¡œì¼€ì¼", options=LOCALES)
    sel_categories= st.multiselect("ì¹´í…Œê³ ë¦¬", options=CATEGORIES)
    keyword = st.text_input("í‚¤ì›Œë“œ(ë‚´ìš©/ì›ì¸/ëŒ€ì‘/ë¹„ê³ )")
    limit = st.number_input("ëª©ë¡ í–‰ìˆ˜", min_value=50, max_value=5000, value=500, step=50)

params = {
    "date_from": datetime.combine(date_from, datetime.min.time()),
    "date_to":   datetime.combine(date_to,   datetime.max.time()),
}
where = ["i.started_at BETWEEN :date_from AND :date_to"]
if sel_platforms:
    where.append("i.platform IN :platforms");   params["platforms"]  = tuple(sel_platforms)
if sel_locales:
    where.append("i.locale IN :locales");       params["locales"]    = tuple(sel_locales)
if sel_categories:
    where.append("i.category IN :categories");  params["categories"] = tuple(sel_categories)
if keyword.strip():
    where.append("(i.description LIKE :kw OR i.cause LIKE :kw OR i.response LIKE :kw OR i.note LIKE :kw)")
    params["kw"] = f"%{keyword.strip()}%"
where_sql = " AND ".join(where)

@st.cache_data(ttl=90, show_spinner=False)
def fetch_kpis(where_sql: str, params: dict):
    with engine.connect() as conn:
        total = pd.read_sql(text(
            f"SELECT COUNT(*) cnt FROM incidents i WHERE {where_sql}"
        ), conn, params=params)["cnt"].iloc[0]

        tparams = dict(params)
        tparams["date_from"] = datetime.combine(datetime.now().date(), datetime.min.time())
        tparams["date_to"]   = datetime.combine(datetime.now().date(), datetime.max.time())
        today_cnt = pd.read_sql(text(
            f"SELECT COUNT(*) cnt FROM incidents i WHERE {where_sql}"
        ), conn, params=tparams)["cnt"].iloc[0]

        top_cat_df = pd.read_sql(text(
            f"SELECT i.category, COUNT(*) cnt FROM incidents i "
            f"WHERE {where_sql} GROUP BY i.category ORDER BY cnt DESC LIMIT 1"
        ), conn, params=params)
        top_cat = (top_cat_df["category"].iloc[0], int(top_cat_df["cnt"].iloc[0])) if not top_cat_df.empty else ("-", 0)

        plat_df = pd.read_sql(text(
            f"SELECT i.platform, COUNT(*) cnt FROM incidents i "
            f"WHERE {where_sql} GROUP BY i.platform ORDER BY cnt DESC"
        ), conn, params=params)
    return total, today_cnt, top_cat, plat_df

@st.cache_data(ttl=90, show_spinner=False)
def fetch_timeseries(where_sql: str, params: dict) -> pd.DataFrame:
    with engine.connect() as conn:
        return pd.read_sql(text(
            f"SELECT DATE(i.started_at) d, COUNT(*) cnt "
            f"FROM incidents i WHERE {where_sql} GROUP BY DATE(i.started_at) ORDER BY d"
        ), conn, params=params)

@st.cache_data(ttl=90, show_spinner=False)
def fetch_list(where_sql: str, params: dict, limit: int) -> pd.DataFrame:
    q = text(f"""
        SELECT i.id, i.started_at, i.ended_at, i.duration, i.platform, i.locale, i.inquiry_count,
               i.category, i.description, i.cause, i.response, i.note, i.created_at, i.updated_at
        FROM incidents i
        WHERE {where_sql}
        ORDER BY i.started_at DESC
        LIMIT :limit
    """)
    p = dict(params); p["limit"] = int(limit)
    with engine.connect() as conn:
        df = pd.read_sql(q, conn, params=p)

    if not df.empty:
        df["started_at"] = pd.to_datetime(df["started_at"]).dt.strftime("%Y-%m-%d %H:%M")
        df["ended_at"]   = df["ended_at"].apply(lambda x: "" if pd.isna(x) else pd.to_datetime(x).strftime("%Y-%m-%d %H:%M"))
        # ê°œí–‰ ì •ê·œí™” (ìœˆë„ìš° \r\n â†’ \n)
        for col in ["description", "cause", "response", "note"]:
            if col in df.columns:
                df[col] = df[col].astype(str).str.replace("\r\n", "\n").str.replace("\r", "\n")
    return df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# KPI ì¹´ë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    total, today_cnt, (top_cat_name, top_cat_cnt), plat_df = fetch_kpis(where_sql, params)
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ì´ ê±´ìˆ˜", f"{total:,}")
    c2.metric("ì˜¤ëŠ˜ ê±´ìˆ˜", f"{today_cnt:,}")
    c3.metric("ìµœë‹¤ ì¹´í…Œê³ ë¦¬", top_cat_name, delta=f"{top_cat_cnt:,}ê±´")
    with c4:
        st.write("í”Œë«í¼ë³„")
        if not plat_df.empty:
            st.altair_chart(
                alt.Chart(plat_df).mark_bar().encode(
                    x=alt.X('platform:N', sort='-y'), y='cnt:Q', tooltip=['platform','cnt']
                ),
                use_container_width=True
            )
        else:
            st.info("ë°ì´í„° ì—†ìŒ")
except Exception as e:
    st.warning(f"KPI ë¡œë”© ì˜¤ë¥˜: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‚¬ê±´ ëª©ë¡ (AgGrid) + í´ë¦­ ì‹œ ìƒì„¸ í‘œì‹œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ“„ ì‚¬ê±´ ëª©ë¡ (ì¤„ë°”ê¿ˆ í‘œì‹œ & í´ë¦­ìœ¼ë¡œ ìƒì„¸ ì—´ê¸°)")

if "selected_id" not in st.session_state:
    st.session_state.selected_id = None

list_df = fetch_list(where_sql, params, int(limit))
if list_df.empty:
    st.info("ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    # \n -> <br/> ë Œë”ëŸ¬ (ìë™ ì¤„ë°”ê¿ˆ + ë†’ì´)
    nl2br = JsCode("""
        function(params) {
          if (!params.value) return '';
          return params.value.replace(/\\n/g, '<br/>');
        }
    """)

    gb = GridOptionsBuilder.from_dataframe(list_df)
    gb.configure_selection(selection_mode="single", use_checkbox=False)
    for c in ["description", "cause", "response", "note"]:
        if c in list_df.columns:
            gb.configure_column(c, cellRenderer=nl2br, wrapText=True, autoHeight=True)
    gb.configure_grid_options(domLayout="normal")
    gridOptions = gb.build()

    grid = AgGrid(
        list_df,
        gridOptions=gridOptions,
        update_mode=GridUpdateMode.SELECTION_CHANGED,
        allow_unsafe_jscode=True,
        fit_columns_on_grid_load=True,
        height=520,
    )

    # í–‰ ì„ íƒ ê²°ê³¼
    sel_rows = grid.get("selected_rows", [])
    new_id = sel_rows[0]["id"] if sel_rows else None

    # ì„ íƒ ìƒíƒœ ì—…ë°ì´íŠ¸
    if new_id is not None and new_id != st.session_state.selected_id:
        st.session_state.selected_id = int(new_id)
    elif new_id is None and st.session_state.selected_id is not None:
        st.session_state.selected_id = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìƒì„¸ ë³´ê¸° (ì„ íƒ ì „ì—ëŠ” ë¹„ë…¸ì¶œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("---")
st.subheader("ğŸ” ìƒì„¸ ë³´ê¸°")

if st.session_state.selected_id is None:
    st.caption("ìœ„ í‘œì—ì„œ í–‰ì„ í´ë¦­í•˜ë©´ ìƒì„¸ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
else:
    with engine.connect() as conn:
        detail = pd.read_sql(
            text("SELECT * FROM incidents WHERE id=:id"),
            conn, params={"id": st.session_state.selected_id}
        )
    if detail.empty:
        st.info("í•´ë‹¹ IDì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        row = detail.iloc[0]
        c1, c2, c3 = st.columns([1,1,1])
        with c1:
            st.write(f"**ID**: {int(row['id'])}")
            st.write(f"**ì¹´í…Œê³ ë¦¬**: {row.get('category','')}")
            st.write(f"**í”Œë«í¼/ë¡œì¼€ì¼**: {row.get('platform','')} / {row.get('locale','')}")
        with c2:
            st.write(f"**ì‹œì‘**: {row.get('started_at','')}")
            st.write(f"**ì¢…ë£Œ**: {row.get('ended_at','')}")
            st.write(f"**ì¥ì• ì‹œê°„**: {row.get('duration','')}")
        with c3:
            st.write(f"**ë¬¸ì˜ëŸ‰**: {row.get('inquiry_count','')}")
            st.write(f"**ì‘ì„±**: {row.get('created_at','')}")
            st.write(f"**ìˆ˜ì •**: {row.get('updated_at','')}")

        st.markdown("**ì¥ì• ë‚´ìš©**")
        st.markdown(f"<div style='white-space:pre-wrap'>{row.get('description','') or ''}</div>", unsafe_allow_html=True)
        st.markdown("**ì›ì¸**")
        st.markdown(f"<div style='white-space:pre-wrap'>{row.get('cause','') or ''}</div>", unsafe_allow_html=True)
        st.markdown("**ëŒ€ì‘**")
        st.markdown(f"<div style='white-space:pre-wrap'>{row.get('response','') or ''}</div>", unsafe_allow_html=True)
        st.markdown("**ë¹„ê³ **")
        st.markdown(f"<div style='white-space:pre-wrap'>{row.get('note','') or ''}</div>", unsafe_allow_html=True)

        if st.button("ì„ íƒ í•´ì œ / ìƒì„¸ ë‹«ê¸°", use_container_width=True):
            st.session_state.selected_id = None
            st.experimental_rerun()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê´€ë¦¬: ì„ íƒ ì‚­ì œ & ì—…ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.expander("ğŸ—‘ ê´€ë¦¬: IDë¡œ ì„ íƒ ì‚­ì œ"):
    ids = st.text_input("ì‚­ì œí•  IDë“¤(ì‰¼í‘œë¡œ êµ¬ë¶„)", placeholder="ì˜ˆ: 101,102,120")
    if st.button("ì‚­ì œ ì‹¤í–‰", type="primary"):
        try:
            id_list = [int(x.strip()) for x in ids.split(',') if x.strip()]
            if not id_list:
                st.warning("IDë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            else:
                with engine.begin() as conn:
                    conn.execute(text("DELETE FROM incidents WHERE id IN :ids"), {"ids": tuple(id_list)})
                st.success(f"ì‚­ì œ ì™„ë£Œ: {len(id_list)}ê±´")
                st.cache_data.clear()
        except Exception as e:
            st.error(f"ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")

with st.expander("â¬†ï¸ ê´€ë¦¬: ì—…ë¡œë“œ (CSV/XLSX)"):
    st.caption("ê°€ëŠ¥í•œ ì»¬ëŸ¼: started_at, ended_at, duration, platform, locale, inquiry_count, category, description, cause, response, note")
    file = st.file_uploader("íŒŒì¼ ì„ íƒ", type=["csv", "xlsx", "xls"])

    def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
        df.columns = [str(c).strip().lower() for c in df.columns]
        for dt in ["started_at", "ended_at"]:
            if dt in df.columns:
                df[dt] = pd.to_datetime(df[dt], errors="coerce")
        if "inquiry_count" in df.columns:
            df["inquiry_count"] = pd.to_numeric(df["inquiry_count"], errors="coerce")
        for col in ["ended_at","duration","platform","locale","inquiry_count","cause","response","note"]:
            if col not in df.columns:
                df[col] = None
        required = ["started_at", "category", "description"]
        missing = [c for c in required if c not in df.columns]
        if missing:
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
        # ê°œí–‰ì€ CSV/XLSX ì €ì¥ ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ ë³´ì¡´ë¨(ë”°ì˜´í‘œë¡œ ê°ì‹¸ì§)
        return df[["started_at","ended_at","duration","platform","locale","inquiry_count",
                   "category","description","cause","response","note"]]

    if file is not None:
        try:
            up = pd.read_csv(file) if file.name.lower().endswith(".csv") else pd.read_excel(file)
            up = normalize_df(up)
            with engine.begin() as conn:
                up.to_sql("incidents", conn, if_exists="append", index=False)
            st.success(f"ì—…ë¡œë“œ ì™„ë£Œ: {len(up)}ê±´")
            st.cache_data.clear()
        except Exception as e:
            st.error(f"ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
